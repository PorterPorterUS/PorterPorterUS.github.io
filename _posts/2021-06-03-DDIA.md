---
layout: post
author: Xusheng Ji
title: "DDIA"
tags: System Design
categories: Database System
---

{% include lib/mathjax.html %}


<script type="text/javascript" async
  src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML">
</script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    extensions: [
      "MathMenu.js",
      "MathZoom.js",
      "AssistiveMML.js",
      "a11y/accessibility-menu.js"
    ],
    jax: ["input/TeX", "output/CommonHTML"],
    TeX: {
      extensions: [
        "AMSmath.js",
        "AMSsymbols.js",
        "noErrors.js",
        "noUndefined.js",
      ]
    }
  });
</script>



DDIA=
=====================Single leader replications ==========================
1.写入操作必须通过leader, 然后leader把写入结果传递给所有的follower
2. 读取操作可以通过任意节点，leader或者follower都可以

同步和非同步的follower：
同步的follower: leader发送给follower,需要等待follower的返回才能执行下一步操作
异步的follower：leader发送给follower，之后可以做任何的事情，不需要等待。
通常集群中只有一个同步的follower，为的是怕leader挂掉，follower可以重新担当leader的职责，其他的节点都是异步的follower，为的是可以提升性能。

新加入的节点追赶
首先对leader的数据进行snapshot，然后把snapshot传递给follower，完毕之后follower问leader索要这段时间内产生变化的数据


处理挂机问题：
如果follower挂掉了，重启之后他会查看自己的log处理到哪一步了，然后向leader索要挂机这段时间内产生的数据变化
如果leader挂机了，需要三步，第一步是集群通过timeout来确定leader挂机了，如果follower一段时间内没收到leader的message,那么证明leader挂机。第二步，选举新的leader，一般选取最up-to-date的follower 第三步，client需要把写操作传递给新的leader，一旦old leader恢复了，一定要确认它变为follower。

Replication Logs的实现方式
1.statement-based replication
log记录的是数据库中每条statement(insert,delete,select),但是问题在于，某些statement是non-deterministic的，在不同的时间，或者不同的情况下执行的结果是不一样的，例如 now()或者自增函数，所以单纯的记录statement是行不通的
2.WAL
WAL是很底层的log，描述的是硬盘中哪个block的哪个byte被修改了，如果leader可以把WAL传递给follower，那么follower可以获取相同的数据。问题在于，假如follower和leader使用的storage version不一样，那么对于相同的log会产生不同的结果。如果follower的版本more newer的话，那么可以使用failover的办法重新选举，让这个follower作为新的leader，
3.Logic replication
和WAL不同的是，可以对storage version进行解耦，对于insert,delete,updated有着业务逻辑上的描述。这就允许follower和leader有着不同的storage engine version。

Leader-based replication的问题
replication的作用：可以使用更多的节点处理更多的请求++让一些replicas更接近users++fault tolerance
问题：有一些异步的follower会处于outdated状态，读取这些follower会产生过期数据，另外如果是同步的follower，那么集群如果很大，等待所有follower进行同步非常耗时
解决方案：
1.read-your-write consistency: 如果读取的是用户自己修改的数据，那么就从leader读。如果application大部分都是用户的修改的数据，可以设置时间限制，超过一定的时间会产生lagging，所以就从leader读取，如果replicas不够up-to-date,则从其他follower读取或者等待catch-up之后再读取。
2.时间一致性->单调读consistency: 如果client从replica的位置读取了两次，第一次读的是稍微过期的数据，第二次读的是过期很大的数据，则会产生先看到有评论，第二次再读取发现没有评论。单调读确保这种事情绝不会发生。解决方案就是最好都从一个replica读取。
3.因果一致性，如果Write A写入原因，write B写入结果，如果一个client读取的时候A产生了一些lagging，导致client先看到结果后看到原因。因果一致性确保了 如果写入的时候有顺序，那么读取的时候一定要按照写入的顺序来读取。

最期待的结果是developer不需要担心一致性，一致性应该由数据库来实现，对于单节点系统来说，使用事务transaction是最好的方案，但是性能有问题，所以大家摒弃了single-leader 


========================multiple  leader replications =============================
multi-leaders replications的应用场景：
1.如果集群需要跨越多个data centers的话，应该在每一个data center都设置一个leader,这样可以提升性能++容错++减少网络传输
2.对于offline application, 例如日历，当你在offline的时候操作，当恢复online的时候，需要和services进行同步处理, 你的每一台设备相当于一个leader，那么你的多个设备就像一个multi-leader的data center一样，他们之间需要互相同步
3.对于共同编辑文档的应用，通常情况下来说可以堪称single-leader模式，一个用户在编辑，另外一个用户必须等候解锁，但是为了加速操作，必须允许多个用户共同操作，这就是multi-leaders的模式


multi-leaders处理写入冲突：
在多人共同编辑文档应用中, 如果是single-leader replication,那么第一个writer写入的时候，第二个writer应该被block住，直到第一个写完之后它才能进行写入。
但是在multi-leaders中, 两个writers可以同时写入自己datacenter中的leader，然后在两个leaders进行同步的时候，发现conflict.
解决方案：
1.修改同一个field都转移到相同的leader上
2.给每一个写入操作赋予一个ID，ID大的覆盖掉ID小的写入操作
3.关于multi-leaders的paper，``Conflict-free replicated datatypes (CRDTs)`` ``Mergeable persistent data structure`` ``Operational transformation ``


Multi-leaders replication Topology:
因为多个leaders之间要进行同步策略,那么leaders之间的数据流向是怎么样的呢？
1.Circular
2.Star
3.All-to-all
对于前两种的问题在于，fault-tolerance处理的不好，一个节点挂掉了，其他的节点无法传递信息。每个node都有自己的ID，每次message被一个node接收之后，这条消息就要加上NODEID，直到消息上所有的NODEID都被标注之后，才证明传递完毕
All-to-all的问题在于，某个node收到其余两个node传递来的消息顺序和真实的逻辑顺序不一致，例如先收到结果，再收到原因，这会违反 因果一致性。



=============================leaderless replications ==================================
1.Quorum
对于没有leader的cluster,所有写入操作都要经过所有的nodes,如果收到 (N/2)+1 = w 以上node的回复，就算是写入成功
所有读取操作都要经过所有nodes, 读要读取r个节点, 因为这R个节点中肯定有确保里面有up-to-date的node
N=all nodes, w=r=(N+1)/2(round up), N一般是奇数, 但是如果是读多写少的系统，可以设置w=n,r=1即可

把w,r设置的比较小，虽然会读取stale data, 但是在很多机器挂掉不能使用的情况下，可以提供HA+lower latency

如果w,r 满足了w+r>n, 这种情况下，仍然会导致读到stale data.
1.Sloppy quorum: r,w不再有overlap
2. 多个读写并发产生，如果last winner wins, writes会丢失。
3. 读和写并发产生， 写入有可能没有写完w个节点,读取就开始发生了,所以会读取stale data.
4. 如果读取发生在w个节点上，但是不是所有的节点都写入成功，那么后续的read操作有可能读到最新数据，也可能读不到最新数据
虽然Quorum理论上读取可以读到最新数据，但是实际上会有很多问题。

对于leader-based replication来说，可以很好的monitoring，因为只要计算出当前stale日志的ID和leader日志的ID之间的差距，即可知道落后了多少。


2.Sloppy Quorums and Hinted Handoff
因为每次读写只需要等待w/r个节点, 所以Quorums有一定的容错性，但是网络出现问题，client无法连接w/r个节点，于是无法凑成w+r>n的条件。
这个时候如果开启了sloppy quorums功能可以暂时使用n之外的节点暂时接受读写请求，等到网络恢复再把读写请求转为正常的n个节点(hinted handoff)
所以sloppy quorums仍然要满足w+r>n.


3.处理并发写入
leaderless replication允许同一个client对同一个key进行多次写入，但是不同的node看到的结果顺序很可能不同，节点1看到先A后B，节点2看到先B后A，所以会出现不一致现象。
解决方案：
3.1 last write wins(LWW)
对每个写入操作都加入一个timestamp, 不同的node只以最后一个timestamp为主, 会把前面的数据给覆盖掉，保证数据一致性。Cassandra就是这么做的，但是问题在于，假如我们想保留之前的数据，LWW会把之前的数据覆盖。解决方案是可以使用UUID来做。

4.怎么定义并发写入？？
和时间没有关系，只要两个写入操作有逻辑上的依赖(A:insert where x=1 B:update x to 1)，就必然不是并发写入.
如果没有逻辑上的依赖，可以定义为并发。
1. Client 1 adds milk to the cart. This is the first write to that key, so the server suc‐ cessfully stores it and assigns it version 1. The server also echoes the value back to the client, along with the version number.
2. Client 2 adds eggs to the cart, not knowing that client 1 concurrently added milk (client 2 thought that its eggs were the only item in the cart). The server assigns version 2 to this write, and stores eggs and milk as two separate values. It then returns both values to the client, along with the version number of 2.
3. Client 1, oblivious to client 2’s write, wants to add flour to the cart, so it thinks the current cart contents should be [milk, flour]. It sends this value to the server, along with the version number 1 that the server gave client 1 previously. The server can tell from the version number that the write of [milk, flour] supersedes the prior value of [milk] but that it is concurrent with [eggs]. Thus, the server assigns version 3 to [milk, flour], overwrites the version 1 value [milk], but keeps the version 2 value [eggs] and returns both remaining values to the client.
4. Meanwhile, client 2 wants to add ham to the cart, unaware that client 1 just added flour. Client 2 received the two values [milk] and [eggs] from the server in the last response, so the client now merges those values and adds ham to form a new value, [eggs, milk, ham]. It sends that value to the server, along with the previ‐ ous version number 2. The server detects that version 2 overwrites [eggs] but is concurrent with [milk, flour], so the two remaining values are [milk, flour] with version 3, and [eggs, milk, ham] with version 4.
5. Finally, client 1 wants to add bacon. It previously received [milk, flour] and [eggs] from the server at version 3, so it merges those, adds bacon, and sends the final value [milk, flour, eggs, bacon] to the server, along with the version number 3. This overwrites [milk, flour] (note that [eggs] was already over‐ written in the last step) but is concurrent with [eggs, milk, ham], so the server keeps those two concurrent values.

<img width="1065" alt="截屏2021-05-30 下午12 24 02" src="https://user-images.githubusercontent.com/60555283/120111979-f1e0ab00-c141-11eb-8a89-ba2215250104.png">



4.1 The server maintains a version number for every key, increments the version number every time that key is written, and stores the new version number along with the value written.
4.2 When a client reads a key, the server returns all values that have not been over‐ written, as well as the latest version number. A client must read a key before writing.
4.3 When a client writes a key, it must include the version number from the prior read, and it must merge together all values that it received in the prior read. (The response from a write request can be like a read, returning all current values, which allows us to chain several writes like in the shopping cart example.)
4.4 When the server receives a write with a particular version number, it can over‐ write all values with that version number or below (since it knows that they have been merged into the new value), but it must keep all values with a higher ver‐ sion number (because those values are concurrent with the incoming write).

最后三种一致性model

1.Read-after-write consistency
Users should always see data that they submitted themselves.
2. Monotonic reads
After users have seen the data at one point in time, they shouldn’t later see the data from some earlier point in time.
3. Consistent prefix reads
Users should see the data in a state that makes causal sense: for example, seeing a question and its reply in the correct order.



==========================PARTITION====================















